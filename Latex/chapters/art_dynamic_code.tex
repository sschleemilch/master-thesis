\chapter{Android Dynamic Native Code}\label{chapter:android_dynamic_native_code}

This chapter will cover shortly how to write native code in Android and how
the connection between Java and C/C++ is being established as well as its
integration into Android Studio.
Then there will be a sample application that shows a dynamic native code execution of a native code shared library that can either be shipped within \code{assets/} or can be pulled in from external sources like the web, secure elements and so on.

\section{NDK and Android Studio Integration}\label{section:ndk_integration}
A complete documentation and starting guide about the NDK can be found at \parencite{ndk} and a guide to the integration into Android Studio at \parencite{ndk_integration}.
There is more than one way to integrate the NDK into Android Studio. The one described
in this thesis uses the platform build tools script \code{ndk-build}. Another possible
integration is the use of the gradle experimental plugin and is described in \parencite{gradle_experimental}.
The NDK allows to embed compiled C/C++ in an application. It can be installed via Android Studio which is the default and recommended IDE for Android development.
The result of compiled C/C++ code is of course CPU dependent. Therefore the library has to be cross compiled for 
every possible CPU supported by Android. Possible architectures supported by the NDK are so far:
\begin{itemize}
\item \textbf{arm64-v8a}
\item \textbf{armeabi}
\item \textbf{armeabi-v7a}
\item \textbf{mips}
\item \textbf{mips64}
\item \textbf{x86}
\item \textbf{x86\_64}
\end{itemize}
The common way is that Android compiles every native source code into shared libraries
(\code{*.so}) that can then be loaded from Java code. However, it is also possible to build executable binaries with NDK in theory. Entry point for the build process is an \code{ndk-build} script inside of the installed \code{ndk-bundle/} folder that takes care of calling the cross-compiling toolchains. It can be controlled by Android makefiles (\code{Android.mk}) and does 
expect a specific folder structure to work which is partially created when using Android Studio. An additional \code{jni/} folder has to be created that will hold all the native source code (right click on \code{app/} and choose \code{New->Folder->JNI Folder}). 

From Java, the compiled library can be loaded by using a
\code{System.loadLibrary("MyLib")} call. In order to be able to call methods out 
of that library, the method signatures have to be known and can be declared with 
a \code{native} keyword in addition to the common Java method declaration. It is also a 
common practice to create a new Java class specifying all NDK functions but not a must have. When doing so, a header file for the native source code (\code{*.h}) can be automatically
created by using the \code{javah} command line tool. It includes the necessary JNI
declarations for the specified methods (including the JNIEnv pointer for instance)
and can then be included in the C/C++ source file that can then be implemented as a
usual C/C++ project.

The last necessary thing is to create an \code{Android.mk} makefile for every library as well as \code{Application.mk}. \code{Android.mk} defines the library name that \code{loadLibrary()} expects, lists the source files and defines the outcome (shared library or executable) whereas \code{Application.mk} includes
the libraries to build (\code{APP\_MODULES}) and the architectures to build for
(\code{APP\_ABI}). The \code{build.gradle} has to be adapted as well, defining the
outcome directory path relative to \code{jni/} and \code{android.useDeprecatedNdk = true} needs to be added to \code{gradle.properties} to suppress an error message. 
A \code{ndk-build} call will then compile all sources and creates the libraries
at \code{libs/<archs>}. They can be used out of the box without need to load them by hand
at runtime. All that's needed is the \code{loadLibrary()} call. Physically, those libraries are stored at the same path as the app APK file like introduced earlier. By applying this method, those native libs are shipped together within the application that might not be the intended behavior. A whole NDK sample project with necessary 
pointed out adaption is shown in \autoref{chapter:ndk_sample_project}.

\section{Dynamic Shared Library Loading}\label{section:shared_library_loading}
The process demonstrated in \autoref{section:ndk_integration} is common practice to 
integrate native code into an app but is not really dynamically loaded. Instead
the main idea of dynamical code loading is the distribution of code for instance
after licensing the app or to apply some sort of copy protection mechanisms by hiding
the true functionality. One approach is to use native code as a loading mechanism.
C/C++ has the ability to load shared objects (\code{*.so}) with a method called
\code{dlopen()}. Its signature is shown in \autoref{dlopen_sig}.
\begin{lstlisting}[language=C++, caption=dlopen() Signature, label=dlopen_sig]
void *dlopen(const char *path, int flag)
\end{lstlisting}
Obviously, a path to the library file is needed as well as a flag that defines the binding of variables and methods (lazy, global, \ldots see dlopen()-reference for more information).
But what path should and can be used in the context of apps? A path inside of the APK
for instance is not reference-able as a path string. So generally apps can use different storage options that are listed and shortly described and can also be looked up in
\parencite{storage_options}.
\begin{itemize}
\item \textbf{Shared Preferences} can store data in form of key-value pairs
\item \textbf{Internal Storage} stores private arbitrary data on the device memory at the path
 \code{/data/data/<appPackage>/} that is only accessible by the app itself.
\item \textbf{External Storage} can also store arbitrary data on \code{/sdcard/} but it is not exclusively readable by the initializing app and needs a permission declaration in
the manifest file.
\item \textbf{SQLite Database} provides support for powerful private databases
\item \textbf{Network Connection} can store data on the web 
\end{itemize}
The most suitable option should be the internal storage since the app has unlimited read
write rights and the content is safe from other sources rather then itself. For simplicity and demonstration reasons, the library to load will be stored in the
\code{assets/} folder of the app that also only exists in the APK but is not 
reference-able through a path. It will therefore be copied into the internal storage first. \autoref{internal_init} shows the Java initialization of the path to the final library to load. The \code{getDir()} call generates a new folder within the internal app storage and a file container for the library to load gets created. 
\begin{lstlisting}[language=Java, caption=Internal Storage Initialization, label=internal_init]
File internalStoragePath = new File(getDir("dynamic", Context.MODE_PRIVATE), "mul.so");
\end{lstlisting}
At a next step, the library has to be copied out of the assets folder and into that 
recently created file container for it. Any file within the assets can be opened with an
\code{getAssets().open("file")} call. For the read/write process one can use
\code{BufferedInputStream} and \code{BufferedOutputStream}, shown in 
\autoref{buff_in_out}.
\begin{lstlisting}[language=Java, caption=Buffered Input/Output, label=buff_in_out]
BufferedInputStream bis = null;
OutputStream soWriter = null;
final int BUF_SIZE = 8 * 1024;
try {
    bis = new BufferedInputStream(getAssets().open("mul.so"));
    sWrite = new BufferedOutputStream(new FileOutputStream(internalStoragePath));
    byte [] buf = new byte[BUF_SIZE];
    int len;
    while ((len = bis.read(buf, 0, BUF_SIZE)) > 0){
        sWrite.write(buf, 0, len);
    }
    sWrite.close();
    bis.close();
} catch (IOException e) {
    e.printStackTrace();
}
\end{lstlisting}
Now the program is ready to transform the transition into the native (C/C++) world.
The signature of the native method to call does contain at least the path as a string to
the internal stored file that can be printed with a \code{getAbsolutePath()} call of the
\code{internalStoragePath} file object. Remember that \code{dlopen()} needs that path.
A class ``\code{MyNDK}'' gets created and contains the native declaration of the
``\code{libExe(String path)}'' method as well as a static call of 
\code{System.loadLibrary(``MyLib'')} that takes care of the binding. 
The implementation of \code{libExe()} is shown in \autoref{libexe}. 
\begin{lstlisting}[language=C++, caption=Native libExe(), label=libexe, numbers=left]
JNIEXPORT void JNICALL Java_ma_schleemilch_nativestuff_MyNDK_libExe
        (JNIEnv * env, jobject jobj, jstring path){
        const char *libpath = env->GetStringUTFChars(path, NULL);
        LOGD("Received Path: %s", libpath);
        void* handle;
        const char* error;
        long (*mul)(int, int);

        handle = dlopen(libpath, RTLD_LAZY);
        if (!handle) {
                LOGE("DL Open failed: %s", dlerror());
                return;
        }
        dlerror();
        *(void**)(&mul) = dlsym(handle, "mul");
        if ((error = dlerror())!= NULL) {
                LOGE("DL Error after DLSYM: %s", error);
                return;
        }
        LOGD("# 9*5 = %ld", (*mul)(9,5));
        dlclose(handle);
        remove(libpath);
}
\end{lstlisting}
One short word about logging/debugging: The common \code{printf()} writes to the standard output. A better way of viewing C++ outputs is to use the ADB logging mechanism. Google does include a \code{\_\_android\_log\_print()} function that
has the same behavior as \code{printf()} but writes to the logcat output and 
\code{LOGD()} is a defined makro calling that function. 

The library that will get loaded is a simple multiplication function and a pointer
for it gets initialized at line seven. \code{dlopen()} returns a void pointer and
\code{dlsym()} searches the symbol table of the handle pointed file for the function
given as a string. That call is interesting when comparing C to C++. In 
\parencite{dlopen_howto}, the problem of name mangling in C++ and the combined usage of
\code{dlopen()} is being described in detail.
In short, one will need an ``\code{extern "C"}'' at the \code{mul()} definition in order to make the \code{dlsym()} function to find the method
because C++ does not use only the method name as its symbol but a unique created ID.
So without that extern keyword, \code{dlsym()} fails.
Finally, the \code{mul()} function can be called out of the library.
After that call, \code{dlclose()} has to be executed. It is also possible to remove
the library file after that process that might be useful for copy protection usage.
From the Java perspective, a \code{MyNDK} object needs to be created followed by 
a call of its \code{libExe()} to call and execute the library.

To be able to load a shared object library like this, it obviously needs to be
generated first. One could use an own cross compiler for that or just also use 
the NDK since it includes all necessary tool-chains. 
However some project structure changes have to be made to be able to compile two independent libraries. Each library to compile should have its own folder inside
of \code{jni/} with an \code{Android.mk} each. The greater \code{Android.mk} in
\code{jni/} has to be changed to call all subsequent make files with 
``\code{include \$(call all-subdir-makefiles)}'' and each module to build has to be
added to \code{Application.mk} as well. Gradle needs to know the names of the sub 
directories of \code{jni/} so that ``\code{jni.srcDirs=[]}'' has to be
filled with those folder name strings. As a result of that structure, the compiled
library that will get loaded afterwards also will be saved in the \code{libs/} folder
and shipped within the app when not deleting it. In a scenario where an app requests new
parts and gets them from a server for instance, these libraries should then only be
present server sided. In order to receive the right compiled shared object for every
device, it should add CPU information with its request (e.g. by sending the output
of ``\code{System.getProperty("os.arch")}'').

It is also possible to do that kind of shared object loading directly out of Java
code. Like shown in \autoref{section:ndk_integration}, a static call of 
\code{System.loadLibrary("MyLib")} does the heavy lifting of invoking the library. 
The \code{loadLibrary()} function however does only check specific paths for the given
library name which are specified in \code{java.library.path}, containing 
\code{/vendor/lib} and \code{/system/lib} as well as the path of the app's APK lib
folder. So for dynamic loading, this loading method is not suitable since these
locations can't be accessed unless with root rights. Fortunately there is another
loading function \code{System.load(String s)} that accepts an absolute path to 
the shared object file like the C++ equivalent \code{dlopen()}. Attention must be
paid to naming conventions in \code{loadLibrary()} in comparison to \code{load()}.
Libraries compiled by the NDK are getting a \code{lib} prefix to its actual module
name automatically. It means that \code{System.loadLibrary("MyLib")} invokes a file
that's called \code{libMyLib.so} while the \code{load()} needs directly the physical
stored path name.

Even if Java is also capable of loading shared object libraries at runtime, the 
signatures of the library to load has to be implemented before to be able to call
its methods unlike the C/C++ implementation where symbols can be resolved itself.

It can also be tried to call a whole native activity with the C/C++ method since
a native activity project can be also compiled into an shared object (see NDK
examples ``native-activity''). To invoke the activity, one need to call the
\code{android\_main()} method but when doing so, it turns out that it will cause
a segmentation fault (SIGSEV).


\section{Dynamic Binary Execution}\label{section:dyn_bin_exec}

It could be also interesting to execute binaries directly instead of loading shared objects. To compile them, again the NDK can be used with changing the module's
\code{Android.mk} file by replacing \code{include \$(BUILD\_SHARED\_LIBRARY)} with 
\code{include \$(BUILD\_EXECUTABLE)}. When doing so, there is to mention 
that all modules compiled for 32 Bit systems are executables directly while modules
compiled for 64 Bit are again shared objects (by checking the output of the Linux
\code{file} command line program).
They are dedicated to their interpreters (\code{/system/bin/linker} and \code{/system/bin/linker64}) that will execute them. It does however make a difference since
Android seems like to support only position independent executables (PIE).
PIE's purpose is to be able to execute its code regardless of its absolute address
and \parencite{pie} is an interesting article about the impact of PIEs.
Shared objects are a specific implementation of PIEs. So in case of 32 Bit systems, there will be an error message 
``\code{error: only position independent executables (PIE) are supported.}'' when
compiled as executable without any additions. There is of course a solution for that
by adding a \code{LOCAL\_CFLAGS} entry \code{-fPIE} as well as the \code{LOCAL\_LDFLAGS}
entries \code{-fPIE} and \code{-pie} to its Android makefile. In fact, after adding
those attributes, there is no more difference between that compiled executable 
compared to the shared library counterpart other than it has to contain a
\code{main()} in order to be executed. 

Again, binary execution can be implemented in Java as well as in native C/C++ code.
Java will be used in both cases to fetch the binary file from an arbitrary location that can be determined at runtime or statically (again \code{assets/} 
for demonstration) and writing it into the internal private storage path. By checking the outcome file of that process via \code{adb shell} and ``\code{ls -l}'', the file is of course not marked as executable by default but at least the owner and the group is set right so there
should not be any permission issue.
If the file is not marked as an executable, it will result in a ``can't execute: Permission denied'' message in case of a C++ implementation or an ``IOException'' in case of Java. Fortunately, it can be fixed simply by calling \code{setExecutable(true)}
of the Java \code{File} object representing the binary. 

\subsection{Java Implementation}\label{dyn_bin_java}
The preparation procedure for executing is the same like in the shared object loading
case, means saving the file in its internal storage and delivering a \code{File} object
to work with. A Java \code{Runtime} object has an \code{exec(String s)} function that is capable of execution code given at its absolute path. It does return a \code{Process}
object. At Android, the current runtime can be accessed with a static access of the 
\code{Runtime}'s \code{getRuntime()} function.
That's basically everything needed to make it work. However one will not see any
outputs (like \code{printf()}) of that separately started process.
The documentation of \code{Process} reveals that the subprocess output can be 
fetched with \code{getInputStream()} and its error output with \code{getErrorStream()}.
It can also be checked and waited for the subprocess to finish via \code{waitFor()} 
which should be the normal case when calling a native binary. The final very
compact implementation is shown in \autoref{java_bin_exec}.
\begin{lstlisting}[language=Java, caption=Java Native Exec(), label=java_bin_exec]
Process nativeExe = Runtime.getRuntime().exec(internalPath);
BufferedReader reader = new BufferedReader(new InputStreamReader(nativeExe.getInputStream()));
int read;
char[] buffer = new char[4096];
StringBuffer output = new StringBuffer();
while ((read = reader.read(buffer)) > 0) {
    output.append(buffer, 0, read);
}
reader.close();
// Waits for the command to finish.
nativeExe.waitFor();
String nativeOutput =  output.toString();
Log.d(TAG, "nativeOut: " + nativeOutput);
\end{lstlisting}

\subsection{C/C++ Implementation}\label{dyn_bin_c}
As for C/C++, the implementation is not much more complicated compared to Java.
The main part of execution is a call of \code{popen()} 
(man printed at \parencite{popen}) which expects a command 
given as a char array to execute and the type of its created pipe (read ``r'' or write ``w''). Internally, it uses \code{fork()} and \code{pipe()} for creating the new 
process and executing the given program at its path. It returns a \code{FILE} pointer
whose stream can be read out by \code{fgets()}. The complete C++ implementation
of the behavior is shown in \autoref{cpp_bin_exec}. In order to catch \code{stderr}
the program path string can be extended with the string ``2>\&1'' to detour the error
channel (2) to the common output channel, \code{stdout} (1).
\begin{lstlisting}[language=C++, caption=C++ Native Exec(), label=cpp_bin_exec]
JNIEXPORT void JNICALL Java_ma_schleemilch_nativestuff_MyNDK_binExe (JNIEnv *env, object obj, jstring path)
{
	const char *exepath = env->GetStringUTFChars(path, NULL);
	FILE* fpipe;
	char* command = new char[strlen(exepath) + strlen(" 2>&1") + 1];
	int ind = 0;
	for (int i = 0; i < strlen(exepath); i++){
		command[ind] = exepath[i];
		ind++;
	}
	command[ind++] = ' ';
	command[ind++] = '2';
	command[ind++] = '>';
	command[ind++] = '&';
	command[ind++] = '1';
	command[ind++] = '\0';
	char line[256];
	if (!(fpipe = (FILE*)popen(command, "r"))) return;
	while(fgets(line, sizeof(line), fpipe)){
		LOGD("%s", line);
	}
}
\end{lstlisting}

\section{Dynamic Code Execution from Memory}\label{section:dyn_code_memory}

Until now, dynamic code execution or loading via shared libraries was done
by downloading/copying a file into the internal storage of the app followed
by invoking it which is kind of like caching it. Instead,
it would be also interesting if program code can be invoked directly in and out
of memory. So there need to be inspected if an Android app process has access
to memory and how to read/execute program code out of it.   

\subsection{Android Memory Mapping}\label{section:memory_mapping}
When printing the content of \code{/proc/<PID>/maps} of a Linux process, one
can see virtual memory locations that are assigned to its process. Also,
``\code{self}'' is a specific PID that can be used as a path in a process
to access its own \code{proc/} directory.
An example output of one map entry is shown in \autoref{tab:proc_maps_out} and its explanations are pulled out of a stackoverflow answer to the question at \parencite{proc_maps}.
\begin{table}[htb]
  \caption[Content of /proc/<PID>/maps]{Content of /proc/<PID>/maps}
  \label{tab:proc_maps_out}
  \centering
  \begin{tabular}{l l l l l l}
    \toprule
    address & perms & offset & dev & inode & pathname \\
    \midrule
    6feed000-708ca000 & rw-p & 00000000 & b3:1c & 105876 & /data/.../framework@boot.art \\
    \bottomrule
  \end{tabular}
\end{table}  
The address shows the physical start and end of its mapped section. Permissions
shows how this region can be accessed (common Linux ``\code{rwx}'' permission triple)
and can be marked as private \code{p} or shared \code{s}. If the section
was mapped out of a file, offset describes the offset inside of that file to
the specific region. Device also only applies if mapped from a file and includes
the device number and inode holds its file number. Pathname obviously holds the
path to the file. 

It is also a good way to start to have a look at an Android process as well.
When doing so, it reveals all kind of mapped libraries (which are a lot even 
with a blank activity app and emphasizes that forking of Zygote is efficient), fonts, its own APK and regions that don't have a pathname or just a pseudo name like
``\code{[anon:linker\_alloc]}'' or ``\code{[stack]}''. Generally, a stack holds
data that only persists inside of a function call like initialized arrays and
variables and its content gets automatically released after leaving that function.
The heap however can be used by the programmer to allocate memory
(e.g. with \code{malloc()}) by hand but has to be freed explicitly.
Let's evaluate which mapping sections are used to store heap as well as common stack
elements by creating a native function with a buffer using \code{malloc()}
and a common local integer variable. While \code{malloc()} creates memory areas
without any additional adaption, \code{mmap()} maps a whole file, returns a pointer
to its start address and can set memory protection flags of the mapped area that
are necessary when it shall be executed, written or read later (\code{PROT\_EXEC},
 \code{PROT\_READ},\code{PROT\_WRITE}).
\autoref{r_maps} shows how to read and print the maps content from C++ on logcat.
\begin{lstlisting}[language=C++, caption=Reading /proc/self/maps, label=r_maps]
FILE* fp;
char line[2048];
fp = fopen("/proc/self/maps", "r");
if (fp == NULL){
    LOGE("Could not open /proc/self/maps");
    return;
}
LOGD("Before:\n");
while (fgets(line, 2048, fp) != NULL) {
    if (strstr(line,"triggeredString")){
        LOGD("%s", line);
    }
}
fp->_close;
\end{lstlisting}
Unfortunately, the amount of output lines is limited when using logging via logcat which
implements a ring buffer with a device dependent size (``\code{adb logcat -g}''). That
is a problem when printing the whole memory mapping and can confuse the inspection 
since a ring buffer overwrites itself when overflowing. So either one can use an
adb shell to ``\code{cat /proc/<PID>/maps}'' by hand (root rights needed)
or triggering the logcat output to specific strings. Getting an overview via a whole output and triggering for specific parts via logcat afterward might be the best solution. 
To find the mapping of the executing library, triggering the name library is enough
and its output is shown on top of \autoref{tab:mem_alloc_map}. Three regions
of the library are mapped, for reading, writing and executing each.
\begin{table}[htb]
  \caption[Memory Allocation Mapping]{Memory Allocation Mapping}
  \label{tab:mem_alloc_map}
  \centering
  \begin{tabular}{l l l l l l}
    \toprule
    address & perms & offset & dev & inode & pathname \\
    \midrule
    b39f5000-b39f8000 & r-xp & 00000000 & b3:1c & 187593 & /data/app/.../lib/arm/libMemory.so \\
    b39f8000-b39f9000 & r--p & 00000000 & b3:1c & 187593 & /data/app/.../lib/arm/libMemory.so \\
    b39f9000-b39fa000 & rw-p & 00000000 & b3:1c & 187593 & /data/app/.../lib/arm/libMemory.so \\
    be0c3000-be8c2000 & rw-p & 00000000 & 00:00 & 0      &    [stack]\\
    b3940000-b39c0000 & rw-p & 00000000 & 00:00 & 0      &    [anon:libc\_malloc]\\
    \bottomrule
  \end{tabular}
\end{table}
When creating an integer variable and printing its address afterwards, it appears
that it is located in a ``\code{[stack]}'' marked region that is not included in 
the library mapped range and memory allocations by the \code{malloc()} as well as the
\code{mmap()} function are listed in areas marked as ``\code{[anon:libc\_malloc]}'' 
(also printed in \autoref{tab:mem_alloc_map}).

\subsection{Code Execution}\label{section:code_execution}
To be able to execute code out of memory it has to be dynamically mapped into the
process space. Like in \autoref{section:memory_mapping} deduced, \code{malloc()} or
\code{mmap()} can be used for that purpose. The \code{mmap()} function needs a file
descriptor as input and therefore it has to be cached at an app readable path where
\code{malloc()} is a bit more flexible since it only expects the desired memory size.
A sample implementation, mapping a shared object for both variants using a demonstration path again given from Java can be found in 
\autoref{chapter:so_mem_mapping}.


\section{General Memory Access}\label{section:general_mem_access}